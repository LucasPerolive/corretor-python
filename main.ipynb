{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e34f11",
   "metadata": {},
   "source": [
    "# Importação e leitura do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16fd270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Senai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        1 - Corretor\n",
      "        2 - Probabilidade de acerto do algoritmo\n",
      "        3 - Quanitidade de palavras que o algoritmo conhece\n",
      "Digite a opção: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 148\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124m        1 - Corretor\u001b[39m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124m        2 - Probabilidade de acerto do algoritmo\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124m        3 - Quanitidade de palavras que o algoritmo conhece\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m    146\u001b[0m opcao \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopcao\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDigite a opção: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 148\u001b[0m \u001b[43mswitch_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopcao\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 129\u001b[0m, in \u001b[0;36mswitch_case\u001b[1;34m(case)\u001b[0m\n\u001b[0;32m    123\u001b[0m switch_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopcao1\u001b[39m\u001b[38;5;124m'\u001b[39m: opcao1,\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopcao2\u001b[39m\u001b[38;5;124m'\u001b[39m: avaliador,\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopcao3\u001b[39m\u001b[38;5;124m'\u001b[39m: quant_palavras_artigo\n\u001b[0;32m    127\u001b[0m }\n\u001b[0;32m    128\u001b[0m selected_case \u001b[38;5;241m=\u001b[39m switch_dict\u001b[38;5;241m.\u001b[39mget(case)\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselected_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 101\u001b[0m, in \u001b[0;36mavaliador\u001b[1;34m(testes, vocabulario)\u001b[0m\n\u001b[0;32m     99\u001b[0m desconhecida \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m correta, errada \u001b[38;5;129;01min\u001b[39;00m testes:\n\u001b[1;32m--> 101\u001b[0m     palavra_corrigida \u001b[38;5;241m=\u001b[39m \u001b[43mcorretor\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrada\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     desconhecida \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (correta \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m vocabulario)\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m palavra_corrigida \u001b[38;5;241m==\u001b[39m correta:\n",
      "Cell \u001b[1;32mIn[23], line 83\u001b[0m, in \u001b[0;36mcorretor\u001b[1;34m(palavra, vocabulario)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m palavra \u001b[38;5;129;01min\u001b[39;00m vocabulario:\n\u001b[0;32m     82\u001b[0m         candidatos\u001b[38;5;241m.\u001b[39mappend(palavra)\n\u001b[1;32m---> 83\u001b[0m palavra_correta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidatos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobabilidade\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m palavra_correta\n",
      "Cell \u001b[1;32mIn[23], line 70\u001b[0m, in \u001b[0;36mprobabilidade\u001b[1;34m(palavra_gerada)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprobabilidade\u001b[39m(palavra_gerada):\n\u001b[1;32m---> 70\u001b[0m     frequencia \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFreqDist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlista_normalizada\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     total_palavras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lista_normalizada))\n\u001b[0;32m     72\u001b[0m     frequencia\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\probability.py:102\u001b[0m, in \u001b[0;36mFreqDist.__init__\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    Construct a new frequency distribution.  If ``samples`` is\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    given, then the frequency distribution will be initialized\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    :type samples: Sequence\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     \u001b[43mCounter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Cached number of samples in this FreqDist\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\collections\\__init__.py:577\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(iterable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\probability.py:140\u001b[0m, in \u001b[0;36mFreqDist.update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03mOverride ``Counter.update()`` to invalidate the cached N\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\collections\\__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(iterable)\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m         \u001b[43m_count_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\probability.py:126\u001b[0m, in \u001b[0;36mFreqDist.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mOverride ``Counter.__setitem__()`` to invalidate the cached N\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setitem__\u001b[39m(key, val)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "with open(\"artigos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "# Confere o que eh palavra depois da tokenizacao\n",
    "def separa_palavras(lista_tokens) -> list:\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "# Normalização das palavras\n",
    "def normalizacao(lista_palavras) -> list:\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada\n",
    "\n",
    "# Funcao de possibilidades\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def substitui_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E+ letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def inverter_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "# Gerador de palavras\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += substitui_caracteres(fatias)\n",
    "    palavras_geradas += inverter_caracteres(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "# Corrige e paga a palavra mais provavel de ser a correta\n",
    "def probabilidade(palavra_gerada):\n",
    "    frequencia = nltk.FreqDist(lista_normalizada)\n",
    "    total_palavras = len(set(lista_normalizada))\n",
    "    frequencia.most_common(10)\n",
    "    return frequencia[palavra_gerada]/total_palavras\n",
    "\n",
    "def corretor(palavra, vocabulario = set(lista_normalizada)):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "# Ver a probabilade de acerto\n",
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\", encoding=\"utf-8\")\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "def avaliador(testes = lista_teste, vocabulario = set(lista_normalizada)):\n",
    "    print(\"Calculando a taxa de acerto...\")\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            palavra_corrigida = corretor(errada)\n",
    "            if palavra_corrigida == correta:\n",
    "                acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecida é {taxa_desconhecida}%\")\n",
    "\n",
    "# Apresentacao\n",
    "def quant_palavras_artigo():\n",
    "    print(f'O número de palavras no artigo é de: {len(lista_palavras)}')\n",
    "\n",
    "def opcao1():\n",
    "    palavra = corretor(input('Palavra que deseja corrigir: '))\n",
    "    print(palavra)\n",
    "    \n",
    "# Opcoes de escolha\n",
    "def switch_case(case):\n",
    "    switch_dict = {\n",
    "        'opcao1': opcao1,\n",
    "        'opcao2': avaliador,\n",
    "        'opcao3': quant_palavras_artigo\n",
    "    }\n",
    "    selected_case = switch_dict.get(case)\n",
    "    return selected_case()\n",
    "\n",
    "\n",
    "if 'lista_tokens' not in locals():\n",
    "    print('Aprendendo as palavras ... Isso irá demorar um pouquinho.')\n",
    "    print('Criando tokens do artigo...')\n",
    "    lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "    lista_palavras = separa_palavras(lista_tokens)\n",
    "    print('Normalizando as palavras...')\n",
    "    lista_normalizada = normalizacao(lista_palavras)\n",
    "    lista_teste = cria_dados_teste(\"palavras.txt\")\n",
    "\n",
    "    \n",
    "print('''\n",
    "        1 - Corretor\n",
    "        2 - Probabilidade de acerto do algoritmo\n",
    "        3 - Quanitidade de palavras que o algoritmo conhece''')\n",
    "opcao = 'opcao' + input('Digite a opção: ')\n",
    "\n",
    "switch_case(opcao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a18035d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

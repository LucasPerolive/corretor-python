{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e34f11",
   "metadata": {},
   "source": [
    "# Importação e leitura do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16fd270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Senai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        1 - Corretor\n",
      "        2 - Probabilidade de acerto do algoritmo\n",
      "        3 - Quanitidade de palavras que o algoritmo conhece\n",
      "Digite a opção: 1\n",
      "Palavra que deseja corrigir: cachoro\n",
      "cachorro\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "with open(\"artigos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "# Confere o que eh palavra depois da tokenizacao\n",
    "def separa_palavras(lista_tokens) -> list:\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "# Normalização das palavras\n",
    "def normalizacao(lista_palavras) -> list:\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada\n",
    "\n",
    "# Funcao de possibilidades\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def substitui_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E+ letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def inverter_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "# Gerador de palavras\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += substitui_caracteres(fatias)\n",
    "    palavras_geradas += inverter_caracteres(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "# Corrige e paga a palavra mais provavel de ser a correta\n",
    "def probabilidade(palavra_gerada):\n",
    "    frequencia = nltk.FreqDist(lista_normalizada)\n",
    "    total_palavras = len(set(lista_normalizada))\n",
    "    frequencia.most_common(10)\n",
    "    return frequencia[palavra_gerada]/total_palavras\n",
    "\n",
    "def corretor(palavra, vocabulario):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "# Ver a probabilade de acerto\n",
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\", encoding=\"utf-8\")\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "def avaliador(testes, vocabulario):\n",
    "    print(\"Calculando a taxa de acerto...\")\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada, vocabulario)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            palavra_corrigida = corretor(errada, vocabulario)\n",
    "            if palavra_corrigida == correta:\n",
    "                acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecida é {taxa_desconhecida}%\")\n",
    "\n",
    "# Apresentacao\n",
    "def quant_palavras_artigo():\n",
    "    print(f'O número de palavras no artigo é de: {len(lista_palavras)}')\n",
    "\n",
    "def opcao1():\n",
    "    palavra = input('Palavra que deseja corrigir: ')\n",
    "    palavra = corretor(palavra, vocabulario)\n",
    "    print(palavra)\n",
    "    \n",
    "def opcao2():\n",
    "    avaliador(lista_teste, vocabulario)\n",
    "    \n",
    "    \n",
    "# Opcoes de escolha\n",
    "def switch_case(case):\n",
    "    switch_dict = {\n",
    "        'opcao1': opcao1,\n",
    "        'opcao2': opcao2,\n",
    "        'opcao3': quant_palavras_artigo\n",
    "    }\n",
    "    selected_case = switch_dict.get(case)\n",
    "    return selected_case()\n",
    "\n",
    "\n",
    "if 'lista_tokens' not in locals():\n",
    "    print('Aprendendo as palavras ... Isso irá demorar um pouquinho.')\n",
    "    print('Criando tokens do artigo...')\n",
    "    lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "    lista_palavras = separa_palavras(lista_tokens)\n",
    "    print('Normalizando as palavras...')\n",
    "    lista_normalizada = normalizacao(lista_palavras)\n",
    "    lista_teste = cria_dados_teste(\"palavras.txt\")\n",
    "    vocabulario  = set(lista_normalizada)\n",
    "    \n",
    "print('''\n",
    "        1 - Corretor\n",
    "        2 - Probabilidade de acerto do algoritmo\n",
    "        3 - Quanitidade de palavras que o algoritmo conhece''')\n",
    "opcao = 'opcao' + input('Digite a opção: ')\n",
    "\n",
    "switch_case(opcao)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
